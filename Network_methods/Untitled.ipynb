{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, \"../Environment/\")\n",
    "import halite_env as Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'halite_env' from '../Environment/halite_env.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(Env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_players = 1\n",
    "map_size = 7 # 7 x 7 map\n",
    "HEnv = Env.HaliteEnv(num_players, map_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Single_ship_env_initialization(map_size, num_players = 1):\n",
    "    HEnv = Env.HaliteEnv(num_players, map_size)\n",
    "    return Env.SingleShipEnv(HEnv, 1, map_size)\n",
    "\n",
    "def check_position(env):\n",
    "    print(env.state[:,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Single_ship_env_initialization(map_size)\n",
    "_ = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines.common import set_global_seeds\n",
    "from stable_baselines import PPO2, ACKTR\n",
    "from stable_baselines.bench import Monitor\n",
    "import stable_baselines\n",
    "#reload(stable_baselines)\n",
    "#from stable_baselines.logger import configure\n",
    "#configure(\"/home/mango/Documents/haliteRL/tensorboard_ppo2\", ['stdout','log','csv','tensorboard'])\n",
    "from hyperparams_opt import hyperparam_optimization\n",
    "\n",
    "\n",
    "MULTI = False\n",
    "COMPARISON = False\n",
    "obs_type = \"raw\"\n",
    "n_timesteps = 100000\n",
    "map_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(map_size, rank, seed=1234, log_dir=None):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param rank: (int) index of the subprocess\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    \"\"\"\n",
    "    if log_dir is None and log_dir != '':\n",
    "        log_dir = \"/tmp/gym/{}/\".format(int(time.time()))\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    def _init():\n",
    "        set_global_seeds(seed + rank)\n",
    "        env = Single_ship_env_initialization(map_size)\n",
    "        \n",
    "        env.seed(seed + rank)\n",
    "        env = Monitor(env, os.path.join(log_dir, str(rank)), allow_early_resets=True)\n",
    "\n",
    "        return env\n",
    "\n",
    "    return _init\n",
    "\n",
    "def evaluate(model, num_steps=1000):\n",
    "    \"\"\"\n",
    "    Evaluate a RL agent\n",
    "    :param model: (BaseRLModel object) the RL Agent\n",
    "    :param num_steps: (int) number of timesteps to evaluate it\n",
    "    :return: (float) Mean reward\n",
    "    \"\"\"\n",
    "    episode_rewards = [[0.0] for _ in range(env.num_envs)]\n",
    "    obs = env.reset()\n",
    "    for i in range(num_steps):\n",
    "        # _states are only useful when using LSTM policies\n",
    "        actions, _states = model.predict(obs)\n",
    "        # here, action, rewards and dones are arrays\n",
    "        # because we are using vectorized env\n",
    "        obs, rewards, dones, info = env.step(actions)\n",
    "\n",
    "        # Stats\n",
    "        for j in range(env.num_envs):\n",
    "            episode_rewards[j][-1] += rewards[j]\n",
    "            if dones[j]:\n",
    "                episode_rewards[j].append(0.0)\n",
    "\n",
    "    mean_rewards = [0.0 for _ in range(env.num_envs)]\n",
    "    n_episodes = 0\n",
    "    for i in range(env.num_envs):\n",
    "        mean_rewards[i] = np.mean(episode_rewards[i])\n",
    "        n_episodes += len(episode_rewards[i])\n",
    "\n",
    "    # Compute mean reward\n",
    "    mean_reward = round(np.mean(mean_rewards), 1)\n",
    "    print(\"Mean reward:\", mean_reward, \"Num episodes:\", n_episodes)\n",
    "\n",
    "    return mean_reward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if MULTI:\n",
    "    num_cpu = 32  # Number of processes to use\n",
    "    # Create the vectorized environment\n",
    "    env = SubprocVecEnv([make_env(map_size, i) for i in range(num_cpu)])\n",
    "else:\n",
    "    # env = SingleSnek(obs_type=\"rgb\", n_food=3)\n",
    "    env = Single_ship_env_initialization(map_size)\n",
    "    # The algorithms require a vectorized environment to run\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "\n",
    "ob = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mango/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: YAMLLoadWarning:\n",
      "\n",
      "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'policy': 'MlpPolicy', 'n_envs': 8, 'n_steps': 128, 'noptepochs': 4, 'nminibatches': 4, 'n_timesteps': 10000000.0, 'learning_rate': 'lin_2.5e-4', 'cliprange': 'lin_0.1', 'vf_coef': 0.5, 'ent_coef': 0.01}\n",
      "8\n",
      "{'policy': 'MlpPolicy', 'n_envs': 8, 'n_steps': 128, 'noptepochs': 4, 'nminibatches': 4, 'n_timesteps': 10000000.0, 'learning_rate': 'lin_2.5e-4', 'cliprange': 'lin_0.1', 'vf_coef': 0.5, 'ent_coef': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open('hyperparams.yml', 'r') as f:\n",
    "            hyperparams_dict = yaml.load(f)\n",
    "            hyperparams = hyperparams_dict['halite']\n",
    "\n",
    "print(hyperparams)\n",
    "print(hyperparams.get('n_envs', 1))\n",
    "print(hyperparams)\n",
    "\n",
    "#hyperparams.get('n_envs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from stable_baselines import PPO2, A2C, ACER, ACKTR, DQN, HER, DDPG, TRPO, SAC\n",
    "\n",
    "ALGOS = {\n",
    "    'a2c': A2C,\n",
    "    'acer': ACER,\n",
    "    'acktr': ACKTR,\n",
    "    'dqn': DQN,\n",
    "    'ddpg': DDPG,\n",
    "    'her': HER,\n",
    "    'sac': SAC,\n",
    "    'ppo2': PPO2,\n",
    "    'trpo': TRPO\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_ = algo = 'ppo2'\n",
    "normalize = False \n",
    "tensorboard_log = './tensorboard_ppo2/'\n",
    "n_trials = int(1e3)\n",
    "n_timesteps = int(1e6)\n",
    "n_jobs = 12\n",
    "n_envs = 12\n",
    "sampler = 'random' # one of: 'random','tpe'\n",
    "pruner = 'halving' # one of: 'halving', 'median', 'none'\n",
    "seed = int(time.time())\n",
    "\n",
    "def create_env(n_envs):\n",
    "            \"\"\"\n",
    "            Create the environment\n",
    "            :param n_envs: (int)\n",
    "            :return: (gym.Env)\n",
    "            \"\"\"\n",
    "            \n",
    "            global hyperparams\n",
    "\n",
    "            if algo_ in ['dqn', 'ddpg']:\n",
    "                if hyperparams.get('normalize', False):\n",
    "                    print(\"WARNING: normalization not supported yet for DDPG/DQN\")\n",
    "                env = gym.make(env_id)\n",
    "                env.seed(seed)\n",
    "            else:\n",
    "                if n_envs == 1:\n",
    "                    env = DummyVecEnv([make_env(map_size, 0, seed)])\n",
    "                else:\n",
    "                    # env = SubprocVecEnv([make_env(env_id, i, args.seed) for i in range(n_envs)])\n",
    "                    # On most env, SubprocVecEnv does not help and is quite memory hungry\n",
    "                    env = DummyVecEnv([make_env(map_size, i, seed) for i in range(n_envs)])\n",
    "                if normalize:\n",
    "                    if args.verbose > 0:\n",
    "                        if len(normalize_kwargs) > 0:\n",
    "                            print(\"Normalization activated: {}\".format(normalize_kwargs))\n",
    "                        else:\n",
    "                            print(\"Normalizing input and reward\")\n",
    "                    env = VecNormalize(env, **normalize_kwargs)\n",
    "            # Optional Frame-stacking\n",
    "            if hyperparams.get('frame_stack', False):\n",
    "                n_stack = hyperparams['frame_stack']\n",
    "                env = VecFrameStack(env, n_stack)\n",
    "                print(\"Stacking {} frames\".format(n_stack))\n",
    "                del hyperparams['frame_stack']\n",
    "            return env\n",
    "\n",
    "\n",
    "def create_model(*_args, **kwargs):\n",
    "                \"\"\"\n",
    "                Helper to create a model with different hyperparameters\n",
    "                \"\"\"\n",
    "                return ALGOS[algo](env=create_env(n_envs), tensorboard_log=tensorboard_log,\n",
    "                                        verbose=0, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler: random - Pruner: halving\n",
      "WARNING:tensorflow:From /home/mango/.local/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/mango/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/mango/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/mango/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-06-30 22:36:11,293] Setting status of trial#4 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:36:11,302] Setting status of trial#6 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:36:17,850] Setting status of trial#1 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:36:40,751] Setting status of trial#10 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:36:52,878] Setting status of trial#5 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:38:41,485] Setting status of trial#9 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:40:12,520] Setting status of trial#2 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:40:14,354] Setting status of trial#11 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:40:25,580] Setting status of trial#7 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:46:02,664] Setting status of trial#13 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:46:04,387] Setting status of trial#14 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:46:38,943] Setting status of trial#15 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:46:48,623] Setting status of trial#16 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:48:58,468] Setting status of trial#17 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:49:59,736] Setting status of trial#20 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:50:21,285] Setting status of trial#12 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:50:34,964] Setting status of trial#18 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:51:53,013] Setting status of trial#19 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:56:39,264] Setting status of trial#21 as TrialState.PRUNED. \n",
      "[I 2019-06-30 22:57:25,338] Setting status of trial#24 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:00:27,860] Setting status of trial#28 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:00:54,145] Setting status of trial#26 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:01:11,438] Setting status of trial#27 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:03:17,254] Setting status of trial#25 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:11:19,721] Setting status of trial#32 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:12:02,311] Setting status of trial#34 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:22:35,865] Setting status of trial#36 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:33:19,740] Setting status of trial#38 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:42:28,464] Setting status of trial#35 as TrialState.PRUNED. \n",
      "[I 2019-06-30 23:54:52,417] Setting status of trial#40 as TrialState.PRUNED. \n",
      "[I 2019-07-01 00:06:07,300] Setting status of trial#41 as TrialState.PRUNED. \n",
      "[I 2019-07-01 01:28:01,817] Finished trial#0 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 01:30:28,286] Finished trial#3 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 01:39:18,802] Setting status of trial#43 as TrialState.PRUNED. \n",
      "[I 2019-07-01 01:44:21,767] Setting status of trial#44 as TrialState.PRUNED. \n",
      "[I 2019-07-01 01:47:10,710] Finished trial#8 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 01:57:09,310] Finished trial#22 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 01:58:10,847] Finished trial#23 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 01:58:56,144] Setting status of trial#47 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:00:07,817] Finished trial#29 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 02:02:15,987] Finished trial#31 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 02:05:23,449] Finished trial#33 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 02:06:52,093] Setting status of trial#48 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:08:01,706] Setting status of trial#49 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:12:11,218] Setting status of trial#52 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:17:41,363] Finished trial#30 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 02:18:31,581] Setting status of trial#55 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:18:39,268] Finished trial#37 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 02:22:32,335] Setting status of trial#56 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:29:46,976] Setting status of trial#57 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:32:49,803] Setting status of trial#58 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:33:37,656] Setting status of trial#60 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:41:38,904] Setting status of trial#61 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:43:44,478] Setting status of trial#63 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:47:24,154] Setting status of trial#62 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:51:51,833] Finished trial#39 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 02:52:04,082] Setting status of trial#64 as TrialState.PRUNED. \n",
      "[I 2019-07-01 02:55:42,445] Setting status of trial#65 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:01:39,645] Setting status of trial#66 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:02:16,097] Setting status of trial#68 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:02:48,766] Setting status of trial#67 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:06:14,350] Setting status of trial#69 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:13:35,879] Setting status of trial#72 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:14:06,985] Setting status of trial#71 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:15:56,965] Setting status of trial#70 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:15:58,745] Finished trial#42 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 03:16:38,923] Setting status of trial#73 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:24:50,949] Setting status of trial#74 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:25:51,407] Setting status of trial#76 as TrialState.PRUNED. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-07-01 03:25:58,970] Setting status of trial#77 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:35:59,025] Setting status of trial#79 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:37:08,584] Setting status of trial#80 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:46:39,978] Setting status of trial#82 as TrialState.PRUNED. \n",
      "[I 2019-07-01 03:47:53,464] Setting status of trial#83 as TrialState.PRUNED. \n",
      "[I 2019-07-01 05:11:14,782] Finished trial#50 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 05:12:58,181] Finished trial#45 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 05:22:24,346] Finished trial#46 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 05:26:14,237] Finished trial#54 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 05:28:26,112] Finished trial#59 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 05:32:43,854] Setting status of trial#88 as TrialState.PRUNED. \n",
      "[I 2019-07-01 05:38:56,817] Setting status of trial#90 as TrialState.PRUNED. \n",
      "[I 2019-07-01 05:39:29,581] Finished trial#51 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 05:40:38,571] Setting status of trial#89 as TrialState.PRUNED. \n",
      "[I 2019-07-01 05:47:05,984] Finished trial#53 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 05:49:26,147] Setting status of trial#92 as TrialState.PRUNED. \n",
      "[I 2019-07-01 05:51:47,543] Setting status of trial#94 as TrialState.PRUNED. \n",
      "[I 2019-07-01 05:57:23,021] Setting status of trial#95 as TrialState.PRUNED. \n",
      "[I 2019-07-01 06:03:43,539] Setting status of trial#97 as TrialState.PRUNED. \n",
      "[I 2019-07-01 06:07:37,614] Setting status of trial#98 as TrialState.PRUNED. \n",
      "[I 2019-07-01 06:18:07,655] Setting status of trial#99 as TrialState.PRUNED. \n",
      "[I 2019-07-01 06:18:31,264] Setting status of trial#100 as TrialState.PRUNED. \n",
      "[I 2019-07-01 06:23:21,399] Finished trial#75 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 06:28:58,682] Setting status of trial#101 as TrialState.PRUNED. \n",
      "[I 2019-07-01 06:54:22,014] Finished trial#81 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 06:55:17,690] Finished trial#78 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 07:05:23,587] Finished trial#84 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 07:07:44,903] Setting status of trial#105 as TrialState.PRUNED. \n",
      "[I 2019-07-01 07:17:50,328] Setting status of trial#108 as TrialState.PRUNED. \n",
      "[I 2019-07-01 07:20:17,819] Finished trial#85 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 07:28:17,916] Setting status of trial#109 as TrialState.PRUNED. \n",
      "[I 2019-07-01 07:42:59,057] Setting status of trial#111 as TrialState.PRUNED. \n",
      "[I 2019-07-01 07:53:35,548] Setting status of trial#112 as TrialState.PRUNED. \n",
      "[I 2019-07-01 08:34:31,793] Finished trial#86 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 08:43:48,593] Finished trial#87 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 08:46:25,039] Setting status of trial#114 as TrialState.PRUNED. \n",
      "[I 2019-07-01 08:55:18,224] Setting status of trial#115 as TrialState.PRUNED. \n",
      "[I 2019-07-01 08:56:53,075] Setting status of trial#116 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:00:55,737] Finished trial#96 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 09:02:06,630] Finished trial#91 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 09:04:35,993] Finished trial#93 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 09:08:52,879] Setting status of trial#117 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:15:36,483] Setting status of trial#119 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:16:42,016] Setting status of trial#121 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:26:35,657] Setting status of trial#123 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:26:45,003] Setting status of trial#124 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:37:23,079] Setting status of trial#125 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:37:56,451] Setting status of trial#126 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:48:01,737] Setting status of trial#127 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:48:31,551] Setting status of trial#128 as TrialState.PRUNED. \n",
      "[I 2019-07-01 09:58:51,603] Setting status of trial#129 as TrialState.PRUNED. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-07-01 10:00:52,913] Finished trial#102 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 10:02:57,214] Finished trial#104 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 10:03:15,320] Finished trial#103 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 10:13:01,830] Setting status of trial#131 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:13:23,679] Setting status of trial#133 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:15:18,705] Setting status of trial#134 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:23:21,193] Setting status of trial#135 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:24:07,121] Setting status of trial#136 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:25:55,826] Setting status of trial#137 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:27:50,460] Finished trial#106 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 10:32:53,835] Setting status of trial#130 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:33:43,528] Finished trial#107 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 10:34:50,016] Setting status of trial#139 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:37:39,095] Setting status of trial#140 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:39:39,377] Setting status of trial#141 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:44:16,136] Setting status of trial#142 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:47:33,628] Finished trial#110 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 10:47:54,195] Setting status of trial#145 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:48:32,094] Setting status of trial#144 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:54:33,181] Setting status of trial#147 as TrialState.PRUNED. \n",
      "[I 2019-07-01 10:58:36,150] Setting status of trial#150 as TrialState.PRUNED. \n",
      "[I 2019-07-01 11:01:34,345] Setting status of trial#148 as TrialState.PRUNED. \n",
      "[I 2019-07-01 11:08:21,280] Setting status of trial#152 as TrialState.PRUNED. \n",
      "[I 2019-07-01 11:14:06,038] Setting status of trial#153 as TrialState.PRUNED. \n",
      "[I 2019-07-01 11:18:02,318] Setting status of trial#154 as TrialState.PRUNED. \n",
      "[I 2019-07-01 11:20:25,417] Finished trial#113 resulted in value: 3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}.\n",
      "[I 2019-07-01 11:25:46,107] Setting status of trial#155 as TrialState.PRUNED. \n",
      "[I 2019-07-01 11:29:58,060] Setting status of trial#157 as TrialState.PRUNED. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  160\n",
      "Best trial:\n",
      "Value:  3.9899966716766357\n",
      "Params: \n",
      "    batch_size: 32\n",
      "    n_steps: 2048\n",
      "    gamma: 0.999\n",
      "    lr: 0.1664672261412471\n",
      "    ent_coef: 0.010130230408794483\n",
      "    cliprange: 0.4\n",
      "    noptepochs: 5\n",
      "    lamdba: 0.95\n"
     ]
    }
   ],
   "source": [
    "if 'n_envs' in hyperparams.keys():\n",
    "    del hyperparams['n_envs']\n",
    "if 'n_timesteps' in hyperparams.keys():\n",
    "    del hyperparams['n_timesteps']\n",
    "\n",
    "data_frame, best_trial = hyperparam_optimization(algo, create_model, create_env, n_trials=n_trials,\n",
    "                                                 n_timesteps=n_timesteps, hyperparams=hyperparams,\n",
    "                                                 n_jobs=n_jobs, sampler_method=sampler, \n",
    "                                                 pruner_method=pruner, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_frame.to_csv('./tensorboard_ppo2/dfppo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "3.9899966716766357. Current best value is 3.9899966716766357 with parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=0, state=<TrialState.COMPLETE: 1>, value=3.9899966716766357, datetime_start=datetime.datetime(2019, 6, 30, 22, 26, 30, 262128), datetime_complete=datetime.datetime(2019, 7, 1, 1, 28, 1, 795135), params={'batch_size': 32, 'n_steps': 2048, 'gamma': 0.999, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 0.4, 'noptepochs': 5, 'lamdba': 0.95}, distributions={'batch_size': CategoricalDistribution(choices=(32, 64, 128, 256)), 'n_steps': CategoricalDistribution(choices=(16, 32, 64, 128, 256, 512, 1024, 2048)), 'gamma': CategoricalDistribution(choices=(0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999)), 'lr': LogUniformDistribution(low=1e-05, high=1), 'ent_coef': LogUniformDistribution(low=1e-08, high=0.1), 'cliprange': CategoricalDistribution(choices=(0.1, 0.2, 0.3, 0.4)), 'noptepochs': CategoricalDistribution(choices=(1, 5, 10, 20, 30, 50)), 'lamdba': CategoricalDistribution(choices=(0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0))}, user_attrs={}, system_attrs={'_number': 0, 'completed_rung_0': 4.190001487731934, 'completed_rung_1': 3.9899966716766357}, intermediate_values={1: 4.190001487731934, 2: 3.9899966716766357, 3: 3.9899966716766357, 4: 3.9899966716766357, 5: 3.9899966716766357, 6: 3.9899966716766357, 7: 3.9899966716766357, 8: 3.9899966716766357, 9: 3.9899966716766357, 10: 3.9899966716766357, 11: 3.9899966716766357, 12: 3.9899966716766357, 13: 3.9899966716766357}, params_in_internal_repr={'batch_size': 0, 'n_steps': 7, 'gamma': 5, 'lr': 0.1664672261412471, 'ent_coef': 0.010130230408794483, 'cliprange': 3, 'noptepochs': 1, 'lamdba': 3}, trial_id=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
