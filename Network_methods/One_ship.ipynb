{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halite "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, \"../Environment/\")\n",
    "import halite_env as Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'halite_env' from '../Environment/halite_env.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(Env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_players = 1\n",
    "map_size = 7 # 7 x 7 map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEnv = Env.HaliteEnv(num_players, map_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Single_ship_env_initialization(map_size, num_players = 1):\n",
    "    HEnv = Env.HaliteEnv(num_players, map_size)\n",
    "    return Env.SingleShipEnv(HEnv, 1, map_size)\n",
    "\n",
    "def check_position(env):\n",
    "    print(env.state[:,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[147   0   0   0   0]\n",
      "  [ 10   0   0   0   0]\n",
      "  [448   0   0   0   0]\n",
      "  [973   0   0   0   0]\n",
      "  [883   0   0   0   0]\n",
      "  [237   0   0   0   0]\n",
      "  [332   0   0   0   0]]\n",
      "\n",
      " [[342   0   0   0   0]\n",
      "  [834   0   0   0   0]\n",
      "  [116   0   0   0   0]\n",
      "  [850   0   0   0   0]\n",
      "  [222   0   0   0   0]\n",
      "  [123   0   0   0   0]\n",
      "  [446   0   0   0   0]]\n",
      "\n",
      " [[302   0   0   0   0]\n",
      "  [188   0   0   0   0]\n",
      "  [463   0   0   0   0]\n",
      "  [970   0   0   0   0]\n",
      "  [483   0   0   0   0]\n",
      "  [867   0   0   0   0]\n",
      "  [289   0   0   0   0]]\n",
      "\n",
      " [[447   0   0   0   0]\n",
      "  [956   0   0   0   0]\n",
      "  [583   0   0   0   0]\n",
      "  [  0   1   0   1   1]\n",
      "  [ 51   0   0   0   0]\n",
      "  [719   0   0   0   0]\n",
      "  [236   0   0   0   0]]\n",
      "\n",
      " [[595   0   0   0   0]\n",
      "  [292   0   0   0   0]\n",
      "  [735   0   0   0   0]\n",
      "  [366   0   0   0   0]\n",
      "  [ 29   0   0   0   0]\n",
      "  [243   0   0   0   0]\n",
      "  [729   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0]\n",
      "  [250   0   0   0   0]\n",
      "  [ 81   0   0   0   0]\n",
      "  [156   0   0   0   0]\n",
      "  [333   0   0   0   0]\n",
      "  [457   0   0   0   0]\n",
      "  [903   0   0   0   0]]\n",
      "\n",
      " [[645   0   0   0   0]\n",
      "  [299   0   0   0   0]\n",
      "  [189   0   0   0   0]\n",
      "  [809   0   0   0   0]\n",
      "  [102   0   0   0   0]\n",
      "  [156   0   0   0   0]\n",
      "  [768   0   0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "env = Single_ship_env_initialization(map_size)\n",
    "env.reset()\n",
    "check_position(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[147   0   0   0   0]\n",
      "  [ 10   0   0   0   0]\n",
      "  [448   0   0   0   0]\n",
      "  [973   0   0   0   0]\n",
      "  [883   0   0   0   0]\n",
      "  [237   0   0   0   0]\n",
      "  [332   0   0   0   0]]\n",
      "\n",
      " [[342   0   0   0   0]\n",
      "  [834   0   0   0   0]\n",
      "  [116   0   0   0   0]\n",
      "  [850   0   0   0   0]\n",
      "  [222   0   0   0   0]\n",
      "  [123   0   0   0   0]\n",
      "  [446   0   0   0   0]]\n",
      "\n",
      " [[302   0   0   0   0]\n",
      "  [188   0   0   0   0]\n",
      "  [463   0   0   0   0]\n",
      "  [970   0   0   0   0]\n",
      "  [483   0   0   0   0]\n",
      "  [867   0   0   0   0]\n",
      "  [289   0   0   0   0]]\n",
      "\n",
      " [[447   0   0   0   0]\n",
      "  [956   0   0   0   0]\n",
      "  [583   0   0   0   0]\n",
      "  [  0   0   0   1   0]\n",
      "  [ 51   0   0   0   0]\n",
      "  [719   0   0   0   0]\n",
      "  [236   0   0   0   0]]\n",
      "\n",
      " [[595   0   0   0   0]\n",
      "  [292   0   0   0   0]\n",
      "  [735   0   0   0   0]\n",
      "  [366   1   0   0   1]\n",
      "  [ 29   0   0   0   0]\n",
      "  [243   0   0   0   0]\n",
      "  [729   0   0   0   0]]\n",
      "\n",
      " [[  0   0   0   0   0]\n",
      "  [250   0   0   0   0]\n",
      "  [ 81   0   0   0   0]\n",
      "  [156   0   0   0   0]\n",
      "  [333   0   0   0   0]\n",
      "  [457   0   0   0   0]\n",
      "  [903   0   0   0   0]]\n",
      "\n",
      " [[645   0   0   0   0]\n",
      "  [299   0   0   0   0]\n",
      "  [189   0   0   0   0]\n",
      "  [809   0   0   0   0]\n",
      "  [102   0   0   0   0]\n",
      "  [156   0   0   0   0]\n",
      "  [768   0   0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "env.step(1)\n",
    "check_position(env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines.common import set_global_seeds\n",
    "from stable_baselines import PPO2, ACKTR\n",
    "import stable_baselines\n",
    "reload(stable_baselines)\n",
    "\n",
    "MULTI = True\n",
    "COMPARISON = False\n",
    "obs_type = \"raw\"\n",
    "n_timesteps = 100000\n",
    "map_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_env(map_size, rank, seed=1234):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param rank: (int) index of the subprocess\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    \"\"\"\n",
    "\n",
    "    def _init():\n",
    "        env = Single_ship_env_initialization(map_size)\n",
    "        env.seed(seed + rank)\n",
    "        return env\n",
    "\n",
    "    set_global_seeds(seed)\n",
    "    return _init\n",
    "\n",
    "def evaluate(model, num_steps=1000):\n",
    "    \"\"\"\n",
    "    Evaluate a RL agent\n",
    "    :param model: (BaseRLModel object) the RL Agent\n",
    "    :param num_steps: (int) number of timesteps to evaluate it\n",
    "    :return: (float) Mean reward\n",
    "    \"\"\"\n",
    "    episode_rewards = [[0.0] for _ in range(env.num_envs)]\n",
    "    obs = env.reset()\n",
    "    for i in range(num_steps):\n",
    "        # _states are only useful when using LSTM policies\n",
    "        actions, _states = model.predict(obs)\n",
    "        # here, action, rewards and dones are arrays\n",
    "        # because we are using vectorized env\n",
    "        obs, rewards, dones, info = env.step(actions)\n",
    "\n",
    "        # Stats\n",
    "        for i in range(env.num_envs):\n",
    "            episode_rewards[i][-1] += rewards[i]\n",
    "            if dones[i]:\n",
    "                episode_rewards[i].append(0.0)\n",
    "\n",
    "    mean_rewards = [0.0 for _ in range(env.num_envs)]\n",
    "    n_episodes = 0\n",
    "    for i in range(env.num_envs):\n",
    "        mean_rewards[i] = np.mean(episode_rewards[i])\n",
    "        n_episodes += len(episode_rewards[i])\n",
    "\n",
    "    # Compute mean reward\n",
    "    mean_reward = round(np.mean(mean_rewards), 1)\n",
    "    print(\"Mean reward:\", mean_reward, \"Num episodes:\", n_episodes)\n",
    "\n",
    "    return mean_reward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if MULTI:\n",
    "    num_cpu = 32  # Number of processes to use\n",
    "    # Create the vectorized environment\n",
    "    env = SubprocVecEnv([make_env(map_size, i) for i in range(num_cpu)])\n",
    "else:\n",
    "    # env = SingleSnek(obs_type=\"rgb\", n_food=3)\n",
    "    env = Single_ship_env_initialization(map_size)\n",
    "    # The algorithms require a vectorized environment to run\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "\n",
    "ob = env.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stable_baselines.PPO2(MlpPolicy, env, verbose=1, tensorboard_log=\"/tmp/halite/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -6.1 Num episodes: 96\n"
     ]
    }
   ],
   "source": [
    "mean_reward_before_train = evaluate(model, num_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00085096736 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.01         |\n",
      "| fps                | 2609          |\n",
      "| nupdates           | 1             |\n",
      "| policy_entropy     | 1.385457      |\n",
      "| policy_loss        | -0.00151566   |\n",
      "| serial_timesteps   | 128           |\n",
      "| time_elapsed       | 2.15e-06      |\n",
      "| total_timesteps    | 4112          |\n",
      "| value_loss         | 0.06463078    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0005664417   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -2.15          |\n",
      "| fps                | 3730           |\n",
      "| nupdates           | 2              |\n",
      "| policy_entropy     | 1.3816876      |\n",
      "| policy_loss        | -0.00090386905 |\n",
      "| serial_timesteps   | 256            |\n",
      "| time_elapsed       | 1.57           |\n",
      "| total_timesteps    | 8224           |\n",
      "| value_loss         | 0.03241264     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0002523807   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -1.09          |\n",
      "| fps                | 3204           |\n",
      "| nupdates           | 3              |\n",
      "| policy_entropy     | 1.3773735      |\n",
      "| policy_loss        | -0.00055076904 |\n",
      "| serial_timesteps   | 384            |\n",
      "| time_elapsed       | 2.67           |\n",
      "| total_timesteps    | 12336          |\n",
      "| value_loss         | 0.024673037    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007501627  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0777       |\n",
      "| fps                | 3596          |\n",
      "| nupdates           | 4             |\n",
      "| policy_entropy     | 1.371366      |\n",
      "| policy_loss        | -0.0011034611 |\n",
      "| serial_timesteps   | 512           |\n",
      "| time_elapsed       | 3.96          |\n",
      "| total_timesteps    | 16448         |\n",
      "| value_loss         | 0.09778508    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00097376306 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.06         |\n",
      "| fps                | 3574          |\n",
      "| nupdates           | 5             |\n",
      "| policy_entropy     | 1.3640337     |\n",
      "| policy_loss        | -0.0015122829 |\n",
      "| serial_timesteps   | 640           |\n",
      "| time_elapsed       | 5.1           |\n",
      "| total_timesteps    | 20560         |\n",
      "| value_loss         | 0.014696144   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0014978234  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.801        |\n",
      "| fps                | 3724          |\n",
      "| nupdates           | 6             |\n",
      "| policy_entropy     | 1.3441248     |\n",
      "| policy_loss        | -0.0017587019 |\n",
      "| serial_timesteps   | 768           |\n",
      "| time_elapsed       | 6.25          |\n",
      "| total_timesteps    | 24672         |\n",
      "| value_loss         | 0.013257736   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0014001773  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0463       |\n",
      "| fps                | 3899          |\n",
      "| nupdates           | 7             |\n",
      "| policy_entropy     | 1.3027868     |\n",
      "| policy_loss        | -0.0009063824 |\n",
      "| serial_timesteps   | 896           |\n",
      "| time_elapsed       | 7.35          |\n",
      "| total_timesteps    | 28784         |\n",
      "| value_loss         | 0.07421161    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00068198727 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.5          |\n",
      "| fps                | 3170          |\n",
      "| nupdates           | 8             |\n",
      "| policy_entropy     | 1.2810439     |\n",
      "| policy_loss        | -0.0007899831 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 8.41          |\n",
      "| total_timesteps    | 32896         |\n",
      "| value_loss         | 0.009921708   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00052103575 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.888        |\n",
      "| fps                | 3911          |\n",
      "| nupdates           | 9             |\n",
      "| policy_entropy     | 1.2643543     |\n",
      "| policy_loss        | -0.0009794146 |\n",
      "| serial_timesteps   | 1152          |\n",
      "| time_elapsed       | 9.71          |\n",
      "| total_timesteps    | 37008         |\n",
      "| value_loss         | 0.010171457   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017119481 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0146       |\n",
      "| fps                | 3615          |\n",
      "| nupdates           | 10            |\n",
      "| policy_entropy     | 1.2448307     |\n",
      "| policy_loss        | -0.0003766979 |\n",
      "| serial_timesteps   | 1280          |\n",
      "| time_elapsed       | 10.8          |\n",
      "| total_timesteps    | 41120         |\n",
      "| value_loss         | 0.072065525   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0001286574   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -1.23          |\n",
      "| fps                | 3907           |\n",
      "| nupdates           | 11             |\n",
      "| policy_entropy     | 1.2454841      |\n",
      "| policy_loss        | -0.00048051818 |\n",
      "| serial_timesteps   | 1408           |\n",
      "| time_elapsed       | 11.9           |\n",
      "| total_timesteps    | 45232          |\n",
      "| value_loss         | 0.0069187526   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003385013  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.989        |\n",
      "| fps                | 3793          |\n",
      "| nupdates           | 12            |\n",
      "| policy_entropy     | 1.2445302     |\n",
      "| policy_loss        | -0.0008947847 |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 12.9          |\n",
      "| total_timesteps    | 49344         |\n",
      "| value_loss         | 0.0060476945  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003520596  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.03          |\n",
      "| fps                | 3454          |\n",
      "| nupdates           | 13            |\n",
      "| policy_entropy     | 1.212155      |\n",
      "| policy_loss        | -0.0007510396 |\n",
      "| serial_timesteps   | 1664          |\n",
      "| time_elapsed       | 14            |\n",
      "| total_timesteps    | 53456         |\n",
      "| value_loss         | 0.054173104   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00072313705 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -1.45         |\n",
      "| fps                | 3543          |\n",
      "| nupdates           | 14            |\n",
      "| policy_entropy     | 1.1995401     |\n",
      "| policy_loss        | -0.0011384765 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 15.2          |\n",
      "| total_timesteps    | 57568         |\n",
      "| value_loss         | 0.005651824   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00076451054 |\n",
      "| clipfrac           | 0.00012207031 |\n",
      "| explained_variance | -1.12         |\n",
      "| fps                | 3999          |\n",
      "| nupdates           | 15            |\n",
      "| policy_entropy     | 1.1672744     |\n",
      "| policy_loss        | -0.0011874188 |\n",
      "| serial_timesteps   | 1920          |\n",
      "| time_elapsed       | 16.4          |\n",
      "| total_timesteps    | 61680         |\n",
      "| value_loss         | 0.006067875   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0023121592  |\n",
      "| clipfrac           | 0.03253174    |\n",
      "| explained_variance | 0.00506       |\n",
      "| fps                | 3622          |\n",
      "| nupdates           | 16            |\n",
      "| policy_entropy     | 1.1756356     |\n",
      "| policy_loss        | -0.0020208845 |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 17.4          |\n",
      "| total_timesteps    | 65792         |\n",
      "| value_loss         | 0.066763915   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00089784525 |\n",
      "| clipfrac           | 0.00018310547 |\n",
      "| explained_variance | -0.863        |\n",
      "| fps                | 3895          |\n",
      "| nupdates           | 17            |\n",
      "| policy_entropy     | 1.2279817     |\n",
      "| policy_loss        | -0.0011435794 |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 18.5          |\n",
      "| total_timesteps    | 69904         |\n",
      "| value_loss         | 0.004595284   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0006634569  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.89         |\n",
      "| fps                | 3773          |\n",
      "| nupdates           | 18            |\n",
      "| policy_entropy     | 1.2433133     |\n",
      "| policy_loss        | -0.0018714822 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 19.6          |\n",
      "| total_timesteps    | 74016         |\n",
      "| value_loss         | 0.004517697   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0046506138  |\n",
      "| clipfrac           | 0.022949219   |\n",
      "| explained_variance | -0.00152      |\n",
      "| fps                | 3593          |\n",
      "| nupdates           | 19            |\n",
      "| policy_entropy     | 1.1700217     |\n",
      "| policy_loss        | -0.0032723963 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 20.7          |\n",
      "| total_timesteps    | 78128         |\n",
      "| value_loss         | 0.06688022    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011416381  |\n",
      "| clipfrac           | 0.0004272461  |\n",
      "| explained_variance | -0.8          |\n",
      "| fps                | 3808          |\n",
      "| nupdates           | 20            |\n",
      "| policy_entropy     | 1.0782537     |\n",
      "| policy_loss        | -0.0009914911 |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 21.8          |\n",
      "| total_timesteps    | 82240         |\n",
      "| value_loss         | 0.0038096446  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0012407559  |\n",
      "| clipfrac           | 0.0012817383  |\n",
      "| explained_variance | -1.14         |\n",
      "| fps                | 3712          |\n",
      "| nupdates           | 21            |\n",
      "| policy_entropy     | 1.046973      |\n",
      "| policy_loss        | -0.0016926044 |\n",
      "| serial_timesteps   | 2688          |\n",
      "| time_elapsed       | 22.9          |\n",
      "| total_timesteps    | 86352         |\n",
      "| value_loss         | 0.0038492116  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00081370247 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00275      |\n",
      "| fps                | 3919          |\n",
      "| nupdates           | 22            |\n",
      "| policy_entropy     | 0.9800661     |\n",
      "| policy_loss        | -0.0005969445 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 24            |\n",
      "| total_timesteps    | 90464         |\n",
      "| value_loss         | 0.041385423   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0002504374   |\n",
      "| clipfrac           | 6.1035156e-05  |\n",
      "| explained_variance | -1.29          |\n",
      "| fps                | 3566           |\n",
      "| nupdates           | 23             |\n",
      "| policy_entropy     | 0.9469554      |\n",
      "| policy_loss        | -0.00040278037 |\n",
      "| serial_timesteps   | 2944           |\n",
      "| time_elapsed       | 25.1           |\n",
      "| total_timesteps    | 94576          |\n",
      "| value_loss         | 0.0034294738   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00082818465 |\n",
      "| clipfrac           | 0.0018310547  |\n",
      "| explained_variance | -0.742        |\n",
      "| fps                | 3586          |\n",
      "| nupdates           | 24            |\n",
      "| policy_entropy     | 0.9229287     |\n",
      "| policy_loss        | -0.0014655343 |\n",
      "| serial_timesteps   | 3072          |\n",
      "| time_elapsed       | 26.2          |\n",
      "| total_timesteps    | 98688         |\n",
      "| value_loss         | 0.00367696    |\n",
      "--------------------------------------\n",
      "Took 27.48s for multiprocessed version - 3638.36 FPS\n",
      "Took 189.64s for single process version - 527.32 FPS\n",
      "Multiprocessed training is 6.90x faster!\n",
      "Mean reward: -6.1 Num episodes: 26\n"
     ]
    }
   ],
   "source": [
    "if MULTI:\n",
    "    # Multiprocessed RL Training\n",
    "    start_time = time.time()\n",
    "    model.learn(n_timesteps)\n",
    "    total_time_multi = time.time() - start_time\n",
    "\n",
    "    print(\n",
    "        \"Took {:.2f}s for multiprocessed version - {:.2f} FPS\".format(\n",
    "            total_time_multi, n_timesteps / total_time_multi\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if COMPARISON:\n",
    "        # Single Process RL Training\n",
    "        env = Single_ship_env_initialization(map_size)\n",
    "        env = DummyVecEnv([lambda: env])\n",
    "\n",
    "        single_process_model = PPO2(MlpPolicy, env, verbose=0)\n",
    "\n",
    "        start_time = time.time()\n",
    "        single_process_model.learn(n_timesteps)\n",
    "        total_time_single = time.time() - start_time\n",
    "\n",
    "        print(\n",
    "            \"Took {:.2f}s for single process version - {:.2f} FPS\".format(\n",
    "                total_time_single, n_timesteps / total_time_single\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"Multiprocessed training is {:.2f}x faster!\".format(\n",
    "                total_time_single / total_time_multi\n",
    "            )\n",
    "        )\n",
    "\n",
    "    mean_reward = evaluate(model, num_steps=10000)\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    model.learn(n_timesteps)\n",
    "    total_time_single = time.time() - start_time\n",
    "\n",
    "    print(\n",
    "        \"Took {:.2f}s for training - {:.2f} FPS\".format(\n",
    "            total_time_single, n_timesteps / total_time_single\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mean_reward = evaluate(model, num_steps=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"halite\")\n",
    "del model\n",
    "model = PPO2.load(\"halite\", env=env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Single_ship_env_initialization(map_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "for i in range(420):\n",
    "    ob = env.step(env.action_space.sample())\n",
    "print(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(env.action_space.sample())\n",
    "#env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gym.spaces.Discrete(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from random import uniform\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "i = 1\n",
    "for _ in range(200):\n",
    "    clear_output(wait=True)\n",
    "    display('Iteration '+str(i)+' Score: '+str(uniform(0, 1)))\n",
    "    time.sleep(0.1)\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
